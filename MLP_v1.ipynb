{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 4), (1, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]]).T\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]]).T\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    global W, b, lr\n",
    "    W = np.random.rand(1, 2)\n",
    "    b = np.random.rand(1)\n",
    "    lr = 0.01\n",
    "\n",
    "forward = lambda x: np.dot(W, x) + b\n",
    "loss = lambda y, y_hat: np.mean((y - y_hat)**2)\n",
    "\n",
    "def train(x, y, epochs=1000):\n",
    "    init()\n",
    "    global W, b\n",
    "    for epoch in range(epochs):\n",
    "        y_hat = forward(x)\n",
    "        loss_val = loss(y, y_hat)\n",
    "        dW = np.mean(np.dot(y-y_hat, x.T), axis=1)\n",
    "        db = np.mean(y-y_hat)\n",
    "        W -= lr * dW\n",
    "        b -= lr * db\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch}, loss: {loss_val:.3f}\")\n",
    "\n",
    "def get_accuracy(x, y):\n",
    "    y_hat = forward(x)\n",
    "    y_hat[y_hat>=0.5] = 1\n",
    "    y_hat[y_hat<0.5] = 0\n",
    "    return np.mean(y_hat==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "epoch: 0, loss: 2.227\n",
      "epoch: 100, loss: 3006.858\n",
      "epoch: 200, loss: 4577929.466\n",
      "epoch: 300, loss: 6970467235.049\n",
      "epoch: 400, loss: 10613404279747.242\n",
      "epoch: 500, loss: 16160229524232746.000\n",
      "epoch: 600, loss: 24605961611603632128.000\n",
      "epoch: 700, loss: 37465640319267433873408.000\n",
      "epoch: 800, loss: 57046102350691185547280384.000\n",
      "epoch: 900, loss: 86859793818390271872829751296.000\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(x, y))\n",
    "train(x, y)\n",
    "print(get_accuracy(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers = [2, 2, 1]\n",
    "\n",
    "def init():\n",
    "    global W, b, lr\n",
    "    W = []\n",
    "    b = []\n",
    "    for i in range(len(Layers)-1):\n",
    "        W.append(np.random.rand(Layers[i+1], Layers[i]))\n",
    "        b.append(np.random.rand(Layers[i+1], 1))\n",
    "    lr = 0.001\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "def relu_derv(x):\n",
    "    return (x>0).astype(np.float32)\n",
    "\n",
    "def forward(x):\n",
    "    global W, b\n",
    "    h = [x]\n",
    "    z = []\n",
    "    for i in range(len(Layers)-1):\n",
    "        z.append(np.dot(W[i], h[-1]) + b[i])\n",
    "        h.append(relu(z[-1]))\n",
    "    return z, h\n",
    "\n",
    "loss = lambda y, y_hat: np.mean((y - y_hat)**2)\n",
    "\n",
    "\n",
    "def train(x, y):\n",
    "    init()\n",
    "    global W, b, lr\n",
    "    for epoch in range(10000):\n",
    "        z, h = forward(x)\n",
    "        y_hat = h[-1]\n",
    "        loss_val = loss(y, y_hat)\n",
    "        dW = []\n",
    "        db = []\n",
    "        g = (y_hat - y)\n",
    "        for i in reversed(range(len(Layers)-2)):\n",
    "            g = g * relu_derv(z[i]) if i < len(Layers)-2 else g\n",
    "            dW.append(np.dot(g, h[i].T))\n",
    "            db.append(np.mean(g, axis=1, keepdims=True))\n",
    "            g = np.dot(W[i].T, g)\n",
    "        for i in range(len(Layers)-2):\n",
    "            W[i] -= lr * dW[-1-i]\n",
    "            b[i] -= lr * db[-1-i]\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch}, loss: {loss_val:.3f}\")\n",
    "        #if get_accuracy(x, y) == 1:\n",
    "            #break\n",
    "def get_accuracy(x, y):\n",
    "    y_hat = forward(x)[1][-1]\n",
    "    y_hat[y_hat>=0.75] = 1\n",
    "    y_hat[y_hat<0.75] = 0\n",
    "    return np.mean(y_hat==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "epoch: 0, loss: 1.075\n",
      "epoch: 100, loss: 0.745\n",
      "epoch: 200, loss: 0.568\n",
      "epoch: 300, loss: 0.444\n",
      "epoch: 400, loss: 0.380\n",
      "epoch: 500, loss: 0.372\n",
      "epoch: 600, loss: 0.365\n",
      "epoch: 700, loss: 0.364\n",
      "epoch: 800, loss: 0.364\n",
      "epoch: 900, loss: 0.364\n",
      "epoch: 1000, loss: 0.364\n",
      "epoch: 1100, loss: 0.363\n",
      "epoch: 1200, loss: 0.363\n",
      "epoch: 1300, loss: 0.363\n",
      "epoch: 1400, loss: 0.363\n",
      "epoch: 1500, loss: 0.363\n",
      "epoch: 1600, loss: 0.363\n",
      "epoch: 1700, loss: 0.363\n",
      "epoch: 1800, loss: 0.363\n",
      "epoch: 1900, loss: 0.363\n",
      "epoch: 2000, loss: 0.362\n",
      "epoch: 2100, loss: 0.362\n",
      "epoch: 2200, loss: 0.362\n",
      "epoch: 2300, loss: 0.362\n",
      "epoch: 2400, loss: 0.362\n",
      "epoch: 2500, loss: 0.362\n",
      "epoch: 2600, loss: 0.362\n",
      "epoch: 2700, loss: 0.362\n",
      "epoch: 2800, loss: 0.362\n",
      "epoch: 2900, loss: 0.362\n",
      "epoch: 3000, loss: 0.362\n",
      "epoch: 3100, loss: 0.362\n",
      "epoch: 3200, loss: 0.362\n",
      "epoch: 3300, loss: 0.362\n",
      "epoch: 3400, loss: 0.361\n",
      "epoch: 3500, loss: 0.361\n",
      "epoch: 3600, loss: 0.361\n",
      "epoch: 3700, loss: 0.361\n",
      "epoch: 3800, loss: 0.361\n",
      "epoch: 3900, loss: 0.361\n",
      "epoch: 4000, loss: 0.361\n",
      "epoch: 4100, loss: 0.361\n",
      "epoch: 4200, loss: 0.361\n",
      "epoch: 4300, loss: 0.361\n",
      "epoch: 4400, loss: 0.361\n",
      "epoch: 4500, loss: 0.361\n",
      "epoch: 4600, loss: 0.361\n",
      "epoch: 4700, loss: 0.361\n",
      "epoch: 4800, loss: 0.361\n",
      "epoch: 4900, loss: 0.361\n",
      "epoch: 5000, loss: 0.361\n",
      "epoch: 5100, loss: 0.361\n",
      "epoch: 5200, loss: 0.361\n",
      "epoch: 5300, loss: 0.361\n",
      "epoch: 5400, loss: 0.361\n",
      "epoch: 5500, loss: 0.361\n",
      "epoch: 5600, loss: 0.361\n",
      "epoch: 5700, loss: 0.361\n",
      "epoch: 5800, loss: 0.361\n",
      "epoch: 5900, loss: 0.361\n",
      "epoch: 6000, loss: 0.360\n",
      "epoch: 6100, loss: 0.360\n",
      "epoch: 6200, loss: 0.360\n",
      "epoch: 6300, loss: 0.360\n",
      "epoch: 6400, loss: 0.360\n",
      "epoch: 6500, loss: 0.360\n",
      "epoch: 6600, loss: 0.360\n",
      "epoch: 6700, loss: 0.360\n",
      "epoch: 6800, loss: 0.360\n",
      "epoch: 6900, loss: 0.360\n",
      "epoch: 7000, loss: 0.360\n",
      "epoch: 7100, loss: 0.360\n",
      "epoch: 7200, loss: 0.360\n",
      "epoch: 7300, loss: 0.360\n",
      "epoch: 7400, loss: 0.360\n",
      "epoch: 7500, loss: 0.360\n",
      "epoch: 7600, loss: 0.360\n",
      "epoch: 7700, loss: 0.360\n",
      "epoch: 7800, loss: 0.360\n",
      "epoch: 7900, loss: 0.360\n",
      "epoch: 8000, loss: 0.360\n",
      "epoch: 8100, loss: 0.360\n",
      "epoch: 8200, loss: 0.360\n",
      "epoch: 8300, loss: 0.360\n",
      "epoch: 8400, loss: 0.360\n",
      "epoch: 8500, loss: 0.360\n",
      "epoch: 8600, loss: 0.360\n",
      "epoch: 8700, loss: 0.360\n",
      "epoch: 8800, loss: 0.360\n",
      "epoch: 8900, loss: 0.360\n",
      "epoch: 9000, loss: 0.360\n",
      "epoch: 9100, loss: 0.360\n",
      "epoch: 9200, loss: 0.360\n",
      "epoch: 9300, loss: 0.360\n",
      "epoch: 9400, loss: 0.360\n",
      "epoch: 9500, loss: 0.360\n",
      "epoch: 9600, loss: 0.360\n",
      "epoch: 9700, loss: 0.360\n",
      "epoch: 9800, loss: 0.360\n",
      "epoch: 9900, loss: 0.360\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(x, y))\n",
    "train(x, y)\n",
    "print(get_accuracy(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8471779  1.00004053 0.94331517 0.8471779 ]]\n"
     ]
    }
   ],
   "source": [
    "print(forward(x)[1][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
